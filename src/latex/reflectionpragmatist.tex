
\hypertarget{reflection-principle-and-the-pragmatic-maxim}{%
\chapter{Reflection Principle and the Pragmatic
Maxim}\label{ch:reflectionmaxim}}

Should my current opinions be constrained by what I expect myself to
belief in the future? This is the concern addressed by the principle of
Reflection, which answers affirmatively:

\begin{quote}
\emph{General Reflection Principle.} My current opinion about event
\(E\) must lie in the range spanned by the possible opinions I may come
to have about \(E\) at later time \(t\), as far as my opinion is
concerned.\footnote{Fraassen Bas C., ``Belief and the Problem of Ulysses
  and the Sirens,'' 16.}
\end{quote}

In the context of probabilistic judgment, Reflection implies that your
current credence, i.e., subjective probability, for the proposition
\(K\) now at \(t1\) must be one of the values you consider as possible
in the future at \(t2\). Van Frassen formulates this general version of
the principle in order to accommodate imprecise probabilities and vague
opinions. I put leave issues regarding imprecise probabilities aside:
when talking about probability, in our context it is sufficient to a
version of Reflection that presupposes precise probability:

\begin{quote}
\emph{Special Reflection Principle.} \(P_t(E|p_{t+x} (E) = r)=r\)
\end{quote}

In words, this formulation says: your subject probability for \(E\)
currently at \(t\), given in the future at time \(t+x\) it will be
\(r\), should also be \(r\). For example, if tomorrow you will come to
believe that the probability of rain is \(0.5\), then your current
probability of rain should also be \(0.5\).

Why should what I think I will believe in the future constrain my
current opinion? The main purpose of this chapter is to demystify
Reflection. In particular, I shall argue for the novel view that
Reflection is a principle of \emph{abductive} reasoning: it regulates
the rationality of the epistemic judgments made in the context of
abduction. My contention is that Reflection is a guiding principle of
what Peirce calls the rationality of deliberate conduct. One criticism
of voluntarism I will focus on is that it does not recognize the
importance of the \emph{context sensitivity} of epistemic judgment.

\hypertarget{moores-paradox-and-self-sabotaging}{%
\section{Moore's Paradox and
Self-Sabotaging}\label{sec:moores-paradox-and-self-sabotaging}}

In section \ref{sec:bayesianism-and-voluntarism}, I have presented a contrast between Orthodox Bayesianism and van
Fraassen's voluntarism:  conditionalization provides a
rational constraint that is explicative in nature, while voluntarism
allows ampliative extrapolation beyond the implication of the evidence.
Still, even if voluntarism presupposes a more liberal conception of
rationality, it must impose least \emph{some} constraints on our
beliefs. This is what the Reflection Principle is supposed to do; it
aims to be a lenient replacement for conditionalization as the overarching principle of
rationality; however, what how we conceive our future selves has to do
with rationality is still rather mysterious. To understand this, we have
to consider the implication of violating Reflection. The possibility of
being Dutch-booked is part of it, but not the full story. The crucial
idea is how the violation of Reflection can lead to the so-called
``Moore's Paradox.''

To begin, we have to distinguish a Moorean \emph{absurdity} and Moore's
\emph{paradox}. A Moorean absurdity arises when a person utters or
thinks that `\(P\) and I don't believe that \(P\)'. For example,

\begin{equation}
	\text{It's raining but I don't believe that it is.}
	\label{eq:moorepararain}
\end{equation}
  
Logically speaking, an utterance or thought like \ref{eq:moorepararain} is not contradictory:
There is no logical connection between my belief in the rain and whether
it is actually raining. This can be demonstrated easily by rephrasing
the same proposition from a third person point of view:

\begin{equation}
	\text{It's raining but Lok does not believe that it is.}
	\label{eq:moorepararain3rdperson}
\end{equation}
 

Unlike \ref{eq:moorepararain}, \ref{eq:moorepararain3rdperson} could easily be a statement about a mistaken judgment on my
part. Perhaps last I checked the sky is absolutely clear, so I refused to believe my friend's truthful report that it's currently raining. Moore's \emph{paradox} is the thought that, even though logic
tells us that such a proposition is perfectly consistent, it seems
absurd for anyone to \emph{assert} such the first-person-perspective
version of the proposition.\footnote{\cite{greenmoore}, 190.} The source of
absurdity is from the conjunction of someone asserting that it is
raining, and the disavowal of the belief in what she just asserts.
Another way to phrase the paradox without appealing to assertion is to
say that a Moorean absurdity is a proposition that is logically
consistent but not believable. That is, I cannot, without succumbing to
absurdity, attribute to myself the belief that it's P and I don't
believe that P.

What does the possibility of Moorean absurdity suggest? Consider this proposal: it is the result of a violation of
established norms. That is, there are implicit standard that govern the
norms between asserting \(P\) and believing \(P\), such that one is
expected to believe what she asserts. Of course, this is not to say that
people do not make deceptive assertion. In such a case the norms are
being exploited for various reasons, but in those cases the speakers do
not announce their intention to deceive. The absurdity comes from the
fact that the norms are being explicitly broken.

One explanation for Moore's paradox is that it signifies a violation of
the underlying norms that govern a \emph{speech act}. The idea is that many of
our linguistic practices carry non-linguistic effects beyond what's being said. Consider a classic example of a speech act: making
a promise. Speech acts theorists argue that there is a normative link
between uttering ``I promise that \(p\)'' and the intention to bring
about \(p\) in the future. A promise could be deemed infelicitous, when
a speaker fail to fulfill the normative conditions necessary for the act
of promising to be successful. Consider J. L. Austin's example: \footnote{\cite{austin}, 54.}

\begin{equation}
	\text{I promise to do \(X\) but I do not intend to do it}
	\label{eq:austinprom}
\end{equation}
 

Like \ref{eq:moorepararain}, this proposition appear
absurd, because they violate the implicit norm that when one makes a
promise, she is expected to have the sincere intention to fulfill the
said promise. More important, the expression of the intention implies that the
promisor is willingly placing oneself under an obligation to the
promisee.\footnote{\cite{searle}, 60.} So to
make the promise, while simultaneously expressing the lack of intention
to carry it out is an absurd act of \emph{self-sabotaging}. 

In section \ref{sec:bayesianism-and-voluntarism}, we noted that, according to the voluntaristic conception of rationality,  any belief that is with the ``bounds of reason'' is rational. Van
Fraassen does not clearly define what those bounds are, but he does
spell out some specific conditions. One is that self-sabotaging is
always irrational, which depends on a distinction between \emph{ex post}
and \emph{ex ante} notions of rational evaluation:

\begin{quote}
Any act of decision can be evaluated in two ways. if we evaluate it
beforehand, we ask how \emph{reasonable} it is, and, afterward, we ask
to what extent it was \emph{vindicated}\ldots{} Therefore a minimal
criterion of reasonableness is that \emph{you should not sabotage your
possibilities of vindication beforehand}\footnote{\cite{bvflaws}, 157.}
\end{quote}

For instance, a promise could be unreasonable---it would unreasonable for the promiser to make the promise---if the action required to
fulfill the promise is impossible, since this means the promiser will
never be vindicated. On the other hand, people do make insincere
promises, and sometimes that would be the rational thing to do: I could
be vindicated in making a insincere promise, if it turned out that doing
saved my life; however, my promise would be absurd, if I were to make an
insincere promise \emph{and} announce my insincerity. 

Van Fraassen's contention is that an assertion of probabilistic judgment, for example:
\begin{equation}
	\text{ It seems more likely to me that it will snow than that it will rain.}
	\label{eq:vfassertion}
\end{equation}
is more like the speech act of making a promise than a description of
the asserter's psychological state.\footnote{\cite{beliefwill} 252--255.} To begin, we
can consider what it would mean for a probabilistic judgment to be a
statement of fact. Ramsey's operationalist definition, as discussed in
the last chapter, seems to fit the bill: an autobiographical report of
one's degrees of belief, elicited through a combination of neutral
propositions and utility evaluation, is a causal effect of the
reporter's disposition to act, so a probabilistic judgment is
interpreted as a description of the agent's psychological state, much
like reports of an object's responses to being scratched by different
substances are descriptions of the object's hardness.

In contrast, consider a passage, which van Fraassen cites approvingly,
from Bruno De Finetti, another progenitor of modern Bayesianism:

\begin{quote}
Any assertion concerning probabilities of events is merely expressing of
somebody's opinion and not itself an event. There is no meaning,
therefore, in asking whether such an assertion is true or false or less
probable.\\
The situation is different, of course, if we are concerned not with the
assertion itself but with whether ``somebody holds or expresses such an
opinion or acts according to it''; for this is a real event or
proposition.\footnote{\cite{definepis}, 189.}
\end{quote}

De Finetti's distinction can be phrased within the framework of speech
acts theory: it is a statement of fact that Lok Chan made a promise to
do \(X\) today at 5PM. It would be true if I did make such a promise,
but it makes no sense to ask if the promise itself is true. I can make a
successful promise by clearly expressing my intention to fulfill my
obligation. De Finetti appears to be saying something quite similar: an
assertion is an \emph{expression} of opinion that itself cannot be true
or false.

In agreement with De Finetti, Van Fraassen argues that making a
probabilistic judgment is more like making a promise and reporting an
autobiographic report about one's psychological state. To make this
argument, van Fraassen tries to demonstrate that this statement

\begin{equation}
		\text{my current degree of belief for \(A\) is \(x\) but it will be $y\neq x$.}
	\label{eq:reflviolation}
\end{equation}
to be an instance of a Moorean absurdity. More specifically, anyone who
asserts the above is said to be \emph{self-sabotaging}. It is evidently
much less clear that the violation of Reflection is an absurdity,
compared to making a promise while announcing the lack of intention to
keep it. 

Perhaps we can first consider the violation in case
of a full belief. Suppose I am invited to the flat earth society meeting
tomorrow that features an extremely persuasive speaker. Knowing that I am always easily swayed by impressive rhetoric, I assert that
\begin{equation}
	\text{ The earth is spherical but I expect to believe in a flat earth
  tomorrow.}
  \label{eq:flatearth}
\end{equation}
Am I sabotaging myself? The argument could go:  if I am willing to assert
fully that the earth is spherical now, I should be able to stand by my
assertion in the future. If I consider my belief in a spherical
earth a rational one and regard being swayed by rhetorics but not evidence to be irrational, then I should simply avoid going to the meeting, in which case I do not expect to believe in flat earth tomorrow.

On the other hand, if I know I will have some perfectly good
reasons to change my mind about the earth being flat, then whatever those good reasons are, \emph{they are also good now}, so I should change current belief in accordance with the expectation of my future epistemic state.

There is a parallel to making promise: if I make a promise today, it is implied that I will keep the promise tomorrow, and a promise shouldn't keep considered as successful if I know perfectly well that I cannot keep my it. For instance, if I made a promise to
someone that I shall never drink alcohol again, I am sabotaging myself
by intentionally putting myself in a situation that will cause my
promise to be broken.

The idea, then, is that making an assertion puts the agent under an
obligation to defend and rationally cultivate the proposition being
asserted. This makes enough sense for full belief, but there is a gap in
carrying this analysis over to degrees of belief:  what is the difference between asserting my degree of belief for \(P\) to be 0.3 and to be
0.7?

Van Fraassen uses betting behavior and Dutch book arguments to fill this
gap.\footnote{\cite{beliefwill}, 244.} The idea is
that asserting a judgment of probability requires me, quite literally,
to put money where my mouth is, and the money involved should be
directly proportional to my degrees of belief. This means that
Reflection implies that what I think my willingness will be in the
future should be my willingness to bet now. Van Fraassen shows that
violating in Reflection will lead to the susceptibility to a 
Dutch book---is a set of bets that will lead to a guaranteed loss
for anyone who accepts it. A Dutch book \emph{argument} is aimed to
demonstrate that the vulnerability to Dutch books a sign of incoherence
and, therefore, irrationality. A Dutch book argument can be made in
support of Reflection by showing that by violating this principle, one
is opening oneself to being ``Dutchbooked''.

More specifically, the argument for Reflection requires a
\emph{Diachronic} Dutch book, which involves a Dutch book
\emph{strategy} to offer the agent bets that would be fair to the agent
at the time, but the acceptance of them will ultimately lead to a loss
to the agent. The trick is to ask the agent to bet on her opinion about
what her future opinion about \(E\) will be, in addition to offering
bets on her opinion about \(E\) itself. If the agent gives an answer
that violates Reflection, then the bookie will be able to make a Dutch
book against her, by offering bets that are fair to her according to her
credences at the time. This is supposed to show that violating
Reflection is an act of self-sabotage. The Dutch book argument will be
elaborated with technical details in the next section, even though it may be
skipped without loss of continuity.

\hypertarget{dutchbook-argument-for-reflection}{%
\section{Dutchbook Argument for
Reflection}\label{dutchbook-argument-for-reflection}}

%A Dutch book involves a set of bets that will lead to a guaranteed loss
%for anyone who accepts it. A Dutch book \emph{argument} is aimed to
%demonstrate that the vulnerability to Dutch books a sign of incoherence
%and, therefore, irrationality. A Dutch book argument can be made in
%support of Reflection by showing that by violating this principle, one
%is opening oneself to being ``Dutchbooked''. More specifically, the
%argument for Reflection requires a \emph{Diachronic} Dutch book, which
%involves a book with a strategy to offer the agent bets that would be
%fair to the agent at the time, but the acceptance of them will
%ultimately lead to a loss to the agent. The trick is to ask the agent to
%bet on her opinion about what her future opinion about \(E\) will be, in
%addition to offering bets on her opinion about \(E\) itself. If the
%agent gives an answer that violates Reflection, then the bookie will be
%able to offer a Dutch book against her.

Initially van Fraasseen uses a Dutch book argument to argue for the
special Reflection principle.\footnote{Fraassen, 244.} However, he has
come to downplay its importance.\footnote{\cite{beliefuly}, 12.} This is partly due to
the decision-theoretic assumptions needed for a Dutch book argument to
succeed, especially on the simplistic model of the agent's willingness
to accept bets.\footnote{James M. Joyce, ``A Nonpragmatic Vindication of
  Probabilism,'' \emph{Philosophy of Science} 65, no. 4 (1998): 575--603}
Nevertheless, it is still useful illustration on how the violation of
Reflection can lead to irrational behavior.

Suppose the Duke basketball team is playing against UNC tonight at 8pm.
It is currently 1pm. Your friend asks you now for your subjective
probability 4 hours later that you will be willing to bet on Duke
winning at odds 2:1. For the sake of clarity, let us define these
propositions:

\begin{centering}

$D$: Duke will win at 8pm. 

$B_{5}$: at $5$pm, P(D) = 1/3.

\end{centering}

Upon reflection, I respond that

\[P(B_5) = 0.4\]

Note that \(P(B_5) = 0.4\) is just a simpler way to write
\(P(p_5(D)=1/3) = 0.4\). That is, currently, there is a probability of
\(0.4\) that in four hours, my credence for Duke winning will be
\(1/3\). Now suppose my friend elicits yet another subjective
probability from me. This time, she would like to know my personal
probability for the eventuality that Duke loses and I come believe at
5pm that their probability to win is \(1/3\). In other words, what is
the probability that \((\neg D \wedge B_{5})\)? Suppose I respond that

\[P(\neg D \wedge B_{5} ) = 0.3\]

From this, \(P(\neg D|B_5)\) is derivable:

\begin{align}
P(\neg D|B_5) &= \frac{P(\neg D \wedge B_5)}{P(B_5)}= \frac{0.3}{0.4}=0.75
\end{align}

And \(P(D|B_5) = 1 - 0.75 = 0.25\). Recall that the current \(t\) is 1,
so \(B_5\) is essentially the same as \(p_{1+4}(D) = 1/3\)---four hours
later, I will come to believe that \(P(D)=1/3\). This means that I have
violated the Reflection, for

\[P(D|p_{5}(D) = 1/3)=0.25 \neq 1/3\]

Now, with this information, my friend then stages a Dutchbook strategy
against me with the following bets:

\begin{longtable}[]{@{}lllr@{}}
\toprule
Bet & Condition & Reward & Cost\tabularnewline
\midrule
\endhead
1 & \((\neg D \wedge B_5)\) & 1 &
\((1)P(\neg D \wedge B_5) =0.3\)\tabularnewline
2 & \(\neg B_5\) & 0.75 & \((0.75)P(B_5)=0.45\)\tabularnewline
3 & \(B_5\) & 0.083 & \((0.083)P(B_5) = 0.03\)\tabularnewline
\bottomrule
\caption{Dutch Book Strategy(Reflection Violated)}
\label{tab:reflectiondutchbooksureloss}
\end{longtable}

The trick is that, in order to devise a Dutchbook against me, the reward
for bet 2 has to be \(P(\neg D | B_5)\), for bet 3 it has to be
\(P(\neg D | B_5)\) minus my subjective probability of \(P(\neg D)\) at
5pm, which is \(0.75-2/3= 0.083\). Since the costs for these bets were
calculated using expected utility, I should regard all of them as being
fair. All three bets cost me \(0.78\) in total. Now, at 5pm, there are
two possible outcomes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  I do not come to believe that \(P(D) = 1/3\): I win bet 2, but lost 1
  and 3. This leads to a net loss of \(-0.78 + 0.75 = -0.03\).
\item
  I come to believe that \(P(D) = 1/3\). I get \(0.083\) for winning bet
  3. Now bet 1 is now contingent on whether or not \(\neg D\). My friend
  now offers me \(2/3\) to buy back that bet, which is fair in my light.
  I sell that bet, which renders the result of the game irrelevant. In
  this case, I have a net loss of \(-0.78+0.083+2/3 = -0.03\).
\end{enumerate}

My initial probability assignment then has rendered me vulnerable to
Dutch books, because I have failed to follow the Reflection Principle.
To see how, consider the situation if I had obeyed Reflection. As
before, suppose that \(P(B_5)\) is 0.4. When my friend asks for my value
for \(P(\neg D \wedge B_5)\), if I had followed Reflection, I would have
realized that \(P(D|B_5)=1/3\). So, assuming independence,
\begin{align*}
P(\neg D \wedge B_5) &= P(\neg D |B_5)\times P(B_5)\\
&= (1-1/3) \times 0.4\\
&= 0.27
\end{align*}

So this means that my pre-Reflection respond---\(0.3\)---was \(0.03\)
higher than it should be, had I followed Reflection, and this
discrepancy is exactly how much I was sure to lose due to being
Dutchbooked.

\begin{longtable}[]{@{}lllr@{}}
\toprule
Bet & Condition & Reward & Cost\tabularnewline
\midrule
\endhead
1 & \((\neg D \wedge B_5)\) & 1 &
\((1)P(\neg D \wedge B_5) =0.27\)\tabularnewline
2 & \(\neg B_5\) & 0.675 &
\((0.75)P(B_5)=0.27\)\tabularnewline
3 & \(B_5\) & 0.008 &
\((0.008)P(B_5) = 0.003\)\tabularnewline
\bottomrule
\caption{Dutch Book Strategy(Reflection Satisfied)}
\label{tab:dutchbooknoloss}
\end{longtable}

\hypertarget{epistemic-failings}{%
\section{Epistemic Failings}\label{epistemic-failings}}

Still, if Reflection is indeed a general normative principle of rationality,
there ought to be reasons to accept it independently of an argument from monetary
loss. Dutch book arguments rely on specific and unrealistic assumptions
about our betting behavior. Some have raised questions about the
reliance on Dutch book arguments, and sought to accomplish what it does with less behavioral assumptions.\footnote{\cite{joycenonprag}} Even van Fraassen himself has
distanced himself from the argument.\footnote{\cite{beliefuly}, 12.}

The key to understanding Reflection intuitively is that it pertains to
the rationality of one's epistemic policies and procedures regarding
revising opinions. To begin, note that what Reflection asks is that our
current opinions should be constrained by what we currently
\emph{consider} to be our future opinions. The idea is that, as a
rational agent, I should see my future opinions as the consequence of my
adhering to my current standard of rationality. If I have good reasons
to think that it is rational for my future self to hold such an opinion,
it should be good enough for my current self \emph{now}.

Thus, consider van Fraassen's remark that

\begin{quote}
	{[}The{]} violation of this Principle is a symptom, within the current
epistemic state, of a deeper defect: that the person holding this
opinion cannot regard him or herself as following a rational policy for
opinion change.\footnote{\cite{beliefuly}, 17.}
\end{quote}


An interpretation of this somewhat difficult passage is this. The assumption  that my future self will epistemically superior is a normative point that we ought to presuppose in our thinking about our future prospects, since rationality 
requires us to cultivate and maintain our opinions over time. Another way 
to articulate this is that Reflection Principle requires a certain \emph{all things being equal} clause being satisfied in our thinking about the rationality of our current and future conducts. In
particular, ``all things being equal'' must include the requirement that
in the time between I am committed to uphold and fulfill the same
standard of rationality, so that my future self will do at least as well
as I am now. For a simple example, suppose that, upon reflection, I
conclude that my future self, with life experience I do not have now,
will find my current spending habit quite irresponsible. If I could
conceive thinking \emph{that} in the future, my rational course of
action \emph{now} to take heed of my future self and revise my spending
habits.

Consider van Fraassen's example of a meteorologist Piero.\footnote{\cite{beliefuly}, 15.} Suppose Piero announces his forecast for the day at 8
a.m. every morning, and that he calculates the probability of rain for
the next day based on his total evidence at 6 p.m. every night. If at 6
p.m. he is confident that, perhaps based on historical data, he will
likely to see evidence at midnight that will drastically change his
current prediction, he should base his opinion what his future self at
midnight \emph{would} have based on his data now, and what he
confidently thinks his future self \emph{would} have.

These two examples demonstrate the two senses in which my future self
could be considered as worthy of my deference: my future self could make
better judgments and my future self could also have more
information.\footnote{\cite{elgadisagreement}, 481.}

For instance, consider some well-known counterexamples to Reflection.
They often involve cases in which I expect myself to make worse
epistemic judgments: in the future, I might lose information, and I
might be worse at making judgments. A prominent example of information
loss is that one may reasonably anticipate future memory loss, so it
would be reasonable not to defer to one's future opinion, thereby
violating Reflection.\footnote{\cite{twoprinciplesofbayesian}, 138--41.} The basic idea is that it is not unreasonable to
refrain from relying on future opinions when you are certain that in the
future you will have forgotten some crucial information. To use the
mundane example from the literature: we often forget what we ate one
year ago today, so it is reasonable to expect that one year later that I
will forget what I eat now, but it does not mean that I should defer to
my future self by concluding that I do not know what I ate today.

Another well-known example for violating
Reflection is anticipated impaired judgments.\footnote{\cite{cleverbookies}, 234--37.} David Christense  asks us to
consider a person \(B\) who has taken a state of mind altering drag that
causes one to believe strongly that she could fly. Suppose \(B\) is
considering her probability of being to fly right after taking the drug
but before it has taken effect. She knows in a few minutes she will
believe strongly that she could fly, but it would make sense to violate
Reflection here.

On my view, these counterexamples work by taking Reflection into contexts that we often consider non-epistemic: in general, we are  forgiving in people's epistemic failure, due to our limited capacity. This, I think, is the crucial disanalogy between making a promise and making an epistemic judgment: promises are generally expected to be kept, except for extenuating circumstances; assertions about probabilities or facts are in general not regulated---this is what the memory loss example demonstrated. Similarly, in general we do not take people's partial assertions, e.g., ``it seems to me likely that...'', ``$P$ is \emph{probably} true'', etc., too seriously: we definitely do not expect these assertions obey the laws of probability. We \emph{know} that people don't.\footnote{\cite{prospect}, 263--91}

Failing to discharge the obligation incurred from making a promise often
leads to the loss of credibility, and this is why the promiser has the
incentive to keep the promise (assuming that she cares about her
credibility). The promiser's aversion to the loss of credibility is also
why the promisee can be justified in taking the utterance as a genuine
expression of the promiser's sincerity---no one would take a
pathological lair's promise seriously, since credibility is no longer an
issue. The social practice of making a promise runs on the currency of
credibility.

Is there a similar institution for judgments of probability? To answer
affirmatively, we need to locate a social convention that penalize the
violation of Reflection. In general, however, I do \emph{not} have to
put money where my mouth is. Contrary to van Fraassen's claim, I do not
think making a probabilistic judgment \emph{in general} is like making a
promise. There is a clear social convention in how the norms for
promising are governed via an economy of credibility, but socially we
usually do not hold assertions of probability as being a genuine
expression of intention to consistently maintain the opinion asserted.

The close connection between degrees of belief and the willingness to
bet provides an important clue. In specific decision-theoretical analyses of, say, business decisions, we are entitled to expect a stakeholder will act in accordance with her expected utility theory.  To put the matter more positively, this is also saying that 
Reflection \emph{does} work in some specific context, so if I were to play a game in which I am contractually
obligated to make a probabilistic judgment and accept fair bets. In such
a narrow context, I should obey Reflection, because I \emph{will} incur
a sure loss if I didn't. This suggests to me that Reflection is required only in contrived
settings that makes Dutch book arguments possible---I do not say this as
a criticism, but as a crucial insight to be developed. 

Epistemic judgments are more context-dependent than making promises. This, I think, is unaccounted for by voluntarism. Probabilistic judgment that serves the aim of knowledge is exception to how we usually behave and not a norm. Therefore, my proposal is that, instead of trying to demonstrate how Reflection would work in multifarious contexts, we should focus on how Reflection would bear on assertions made \emph{in the different contexts of inquiry}: making conjectures about a phenomenon of interest, verifying a prediction, etc. We need a richer conception of our epistemic practice, which, I suggest, can be found in Peirce's pragmatism, to which we shall now turn.

\hypertarget{the-pragmatic-maxim}{%
\section{The Pragmatic Maxim}\label{the-pragmatic-maxim}}

\hypertarget{operationalism-and-counterfactual-context}{%
\subsection{Operationalism and Counterfactual
Context}\label{operationalism-and-counterfactual-context}}

Discussions of the Pragmatic Maxim often begin with Peirce's ``How to
Make our Ideas Clear'', as it contains perhaps the most well-known
articulation of the principle:

\begin{quote}
Consider what effects, that might conceivably have practical bearings,
we conceive the object of our conception to have. Then, our conception
of these effects is the whole of our conception of the object.\footnote{\cite{makeideasclear}. 266.}
\end{quote}

The Pragmatic Maxim, even on a limited reading,  suggests that
the meaning of a word is tied to some publicly perceivable phenomenon. So, the Pragmatic Maxim can definitely be read to support a kind of
\emph{operationalism}, which holds that the ``practical bearings''
mentioned above refers the \emph{publicly accessible causal effects} of the object denoted
by the word.\footnote{\cite{whatpragwas}, 43.} This operationalism is
motivated by a commitment to define terms in a way that is conducive to
scientific inquiry. Many ideas handed down to us by tradition do not
naturally admit empirical investigation. Thus, we should clarify them so
that questions about them can be resolved by appealing to
evidence.\footnote{\cite{hoover1994}, 292.} The operationalist reading of the Pragmatic
Maxim emphasizes on Peirce's view on how we should analyze our ideas in
service of scientific endeavors.

The operationalist reading of the Pragmatic Maxim may sounds
suspiciously like the logical positivists' verificationism, which says
something along the lines of words owe their meanings entirely to
verifiable sense experience. However, this would be a misreading of the
maxim, as it does not say a concept is reduced to its actual effects;
instead, it states that concepts are delineated by the effects ``that
might \emph{conceivably} have practical bearing, we \emph{conceive} the
object of conception to have''. The distinction between the two is not
verbal. Peirce takes the full understanding of an object - insofar as
all doubts about it is eliminated, to require the knowledge of how just
how it behaved but also how it would behave in counterfactual
situations.

Peirce's emphasis on counterfactuals can be understood as the
\emph{context-sensitivity} of the conditions of success for the
application of concepts. Consider the classic discussion of the
context-sensitivity of counterfactual conditionals by Nelson
Goodman.\footnote{\cite{goodmancounterfactual}
  113--28.} A counterfactual conditional is a proposition about the
states of affair \(C\) that would follow, if the antecedent of the
conditional \(A\) were true. Goodman points out that a small change of
the content of the antecedent would change the truth-condition of the
conditional itself, in a way inconsistent with how material conditionals
behave in formal logic. Consider the following is a property of the
material conditional but not the counterfactual conditional:

\begin{equation}\label{eq:cfconschema}
	\text{`If \(A\), then \(B\)' implies `if \(A\) and \(C\), then \(B\)'}
\end{equation}


This is because the conditional in \ref{eq:cfconschema} is understood as \(A\) cannot be
true without \(B\) being true, so the presence of \(C\) ought not defeat
it. But counterfactual conditionals do not behave this way. Consider:
\begin{equation}\label{eq:cfconextrue}
	 \text{If the match had been struck, it would have been lighted.}
\end{equation}
\begin{equation}\label{eq:cfconexfalse}
	 \text{ If the match had been wet and then struck, it would have been lighted.
}
\end{equation}
Even though {eq:cfconextrue} is true, {eq:cfconexfalse} is not. The point is that
counterfactual conditionals like the above presuppose a certain context.
When I say that \emph{the match would have lighted if it was struck}, I am
assuming that the person to whom I am speaking understood the context
relevant to this statement. If the other person asks whether the match was underwater, I would be entitled to somewhat incredulous, since I would assume that's the context. Thus, we are entitled to claim to have a understanding of the match's lighting behavior, only when we have our ability to pinpoint the exact context in which the counterfactual conditional is true.

While Peirce's operationalism ties our understanding of a concept
to its empirical effects, it does not buy into crude reductionism to the
strictly observable and the physical. For instance, Peirce says that the
point of the diamond example is not a metaphysical reduction of the
property of being hard into nothing but a list facts pertaining the
diamond being scratched, but an epistemological point about how
properties such as hardness can be probed through learning it
\emph{would} behave under all conceivable scenario, including
counterfactual ones.\footnote{\cite{CP}, 5.453.} Only then we are entitled to say that we have
thoroughly learned what the property of hardness is. Most important,
these facts and counterfacts are evidence \emph{for} the existence of
abstract and theoretical entities, and not a reduction of them.

\hypertarget{inferentialism-and-the-context-of-deliberate-conduct}{%
\subsection{Inferentialism and the Context of Deliberate
Conduct}\label{inferentialism-and-the-context-of-deliberate-conduct}}

It is clear that Peirce often intends the Pragmatic Maxim to be a
principle that guides our analysis of concepts in service of empirical
investigation. But in his later works, Peirce also expresses the
Pragmatic Maxim as a thesis about how we ought to understand the
normative implication of one's \emph{acceptance} of a belief. This is
the \emph{inferentialist} reading of the maxim, which interprets the
term ``practical bearings'' as \emph{how concepts and beliefs bear on
our practice}. That is, the acceptance of a belief puts a constraint on
the agent's other beliefs and her actions.\footnote{\cite{whatpragwas}, 44.} Christopher Hookway's interpretation of the
Pragmatic Maxim is an example of an inferentialist reading:

\begin{quote}
If I believe or assert a proposition, I commit myself to the expectation
that future experience will have a particular character. If this
expectation is disappointed, than I will probably have to abandon the
belief or withdraw the assertion. Clarification of a concept using the
pragmatist principle provides an account of just what commitments I
incur when I believe or assert a proposition in which the concept is
ascribed to something.\footnote{\cite{hookway1}, 60.}
\end{quote}

Consider the following formulation of the Pragmatic Maxim from Peirce's
later work:

\begin{quote}
{[}Pragmatism is{]} the maxim that the entire meaning and significance
of any conception lies in its conceivably practical bearings, - not
certainly altogether in consequences that would influence our conduct so
far as we can force our future circumstances but which in conceivable
circumstances would go to determine how \emph{we should deliberately
act}, and how we should act in a practical way and not merely how we
should act as affirming or denying the conception to be cleared
up.\footnote{Charles S. Peirce, \emph{The Essential Peirce, Volume 2:
  Selected Philosophical Writings (1893-1913)}, ed. Peirce Edition
  Project (Indiana University Press, 1998), 145, my emphasis.}
\end{quote}

One striking difference between these formulations and the one from
``How to Make Our Ideas Clear'' is emphasis on deliberative action and
rational conduct. ``Deliberate conduct,'' Peirce further explains, is
``self-controlled conduct.''\footnote{Peirce, 348.} The crucial idea
here is that since the meaning of a word manifests itself through its
causal and practical effects, a belief, which consists of the use of
these words, should have a practical effect on those who accepts the
belief. But the effect here is not one of a causal one, but a rational
one.

Thus when Peirce identifies belief as habits, he does not mean a blind
response to stimuli but a ``deliberate, or self-controlled,
habit.''\footnote{Peirce, \emph{Collected Papers of Charles Sanders
  Peirce}, 1931, 5.480.} What Peirce has in mind in particular is that
the accepting belief implies a rational constraint on the believer's
future conduct, for ``future facts are the only facts we can, in a
measure, control'', so this is what is meant by the idea that beliefs
can have rationally binding repercussions on our future
conduct.\footnote{Peirce, \emph{The Essential Peirce, Volume 2}, 1998,
  359.}

Putting the two together, what emerges is a more nuanced interpretation
of Reflection: making a probabilistic judgment may imply a certain
commitment, such that I will have to act deliberately in a particular
way that I would not have otherwise. But this normative link is highly
contextual: just like the lighting of a match could fail if one of the
necessary conditions is not met. I will devote the rest of this chapter
into developing this by diving further into Peirce's philosophy.

Peirce's view on the normative dimension of assertion is especially
relevant. According to Peirce, the assertion of a proposition entails a
normative commitment: ``to assert a proposition is to make oneself
responsible for its truth.''\footnote{Peirce, \emph{Collected Papers of
  Charles Sanders Peirce}, 1931, 5.543.} The very idea of responsibility
has both the prospective and deliberative elements that the
inferentialist reading of the pragmatic maxim exploits: to undertake the
responsibility of task usually means the responsible party will
deliberatively carry out the task involved some time in the future.

Peirce also sees a link between asserting a proposition and the
willingness to bet: ``Both are acts whereby the agent deliberately
subjects himself to evil consequences if a certain proposition is not
true.''\footnote{Peirce, \emph{The Essential Peirce, Volume 2}, 1998,
  140.} The analogy Peirce is making here is that the acceptance of a
belief cannot be understood without appealing to normative concepts such
as commitment, intention, and responsibility: to believe that \(p\)
involves the expression of the agent's intention to assume the
responsibility of fulfilling the normative commitments entailed by the
belief. Betting is an instance of this: betting on \(p\) being true
means making a commitment to act a certain way if the proposition were
false: making the bet means the agent is now responsible. For the bet to
be genuine, the bettor must express her intention to pay if she happens
to lose the bet: she either loses money, or, if she refuses to pay,
loses credibility.

Peirce's view then anticipates and overlaps with van Fraassen's
voluntarism. What makes Peirce's view, I think, superior to voluntarism
is his recognition that the normative force of assertion is
\emph{context dependent}. In Peirce's words, the ``measure of
assurance'' implied by an assertion is a function of the context in
which it is asserted\footnote{Peirce, \emph{Collected Papers of Charles
  Sanders Peirce}, 1931, 4.54.} An assertion in the court of law, for
instance, presupposes a high degree of assurance, and implies the
responsibility on the asserter's part to demonstrate its truth:

\begin{quote}
If a man desires to assert anything very solemnly, he takes such steps
as will enable him to go before a magistrate or notary and take a
binding oath to it\ldots{}. it would be \emph{followed by very real
effects, in case the substance of what is asserted should be proved
untrue}\ldots{} if a lie would not endanger the esteem in which the
utterer was held, nor otherwise be apt to entail such real effects he
would avoid, the interpreter would have no reason to believe the
assertion\footnote{Peirce, 5.546 my emphasis.}
\end{quote}

The crucial point here is that there is nothing magical about an
assertion in and of itself: to make an assertion count as a genuine
expression of the intention to assume the responsibility for the truth
of the asserted proposition, the speaker has to enter into a social
context in which the speaker's failure to fulfill this responsible will
lead to ``very real effects'', such as the risk of legal jeopardy.

Thus Peirce recognizes the subtle differences of context make a world of
difference in terms of the normative force implied by the assertion. For
instance,

\begin{quote}
Nobody takes any positive stock in those conventional utterances, such
as ``I am perfectly delighted to see you,'' upon whose falsehood no
punishment at all is visited.\footnote{Peirce, 5.546.}
\end{quote}

Thus, assertions made during ``small talk'' should not be interpreted in
an epistemically meaningful context, and thus are not subject to the
same standard of criticism as a serious assertion. This distinction is
helpful in defending Reflection against the somewhat strange
counterexamples. In the cases of memory loss, in many if not most social
contexts, it is often excusable or expected to be forgetful. Facts
pertaining what one had eaten in the past are rarely relevant in
situation where the speaker's intention will be called into question. On
the other hand, if a speaker is testifying in a court of law under oath,
she is expected to stand by any assertion that is made in future.
Inconsistency due to faulty memory is strictly regulated and punished
through the hearsay rule and cross-examination.\footnote{David
  Greenwald, ``The Forgetful Witness,'' \emph{The University of Chicago
  Law Review} 160, no. 1 (1993): 167.}

\hypertarget{the-abductive-context-of-inquiry}{%
\section{The Abductive Context of
Inquiry}\label{the-abductive-context-of-inquiry}}

Peirce's pragmatism provides a helpful framework to see why rationality
of epistemic judgment cannot be totally captured in voluntarist terms.
James' and, by extension, van Fraassen's voluntarism is based on an
interpretation of the Pragmatic Maxim that, I want to suggest, leads to
a problematic interpretation of Reflection.

Peirce makes a very helpful remark in a letter to James, in response to
receiving a copy of \emph{The Will to Believe}, a book dedicated to
Peirce himself.\footnote{Peirce, \emph{Collected Papers of Charles
  Sanders Peirce}, 1931, 8.250--251.} Peirce points out that James has
conflated the crucial distinction between \emph{provisionally} accepting
a belief for the sake of further inquiry, and accepting a belief without
any evidence. From Peirce's point of view, James has taken the general
lesson of the Pragmatic Maxim, that ``everything is to be tested by its
practical result'', to its logical extreme, that ``mere action as brute
exercise of strength that is the purpose of all.''\footnote{Peirce,
  8.250.}

The thought is that if the Pragmatic Maxim is interpreted as suggesting
that the rationality of the acceptance of beliefs and the application of
concepts is evaluated in terms of whether their practical implications
are satisfied, then one may conclude, as James does, that (some) beliefs
can be justified simply by virtue of committing into the mode of
behavior required by the belief. This is why the central argument in
\emph{The Will to Believe} is that one's belief in God can be justified
as long as one is committed into acting \emph{as if} God exists.

This feature is carried over to van Fraassen's voluntarism. The
analogous move here is the claim that if we treat reports of degrees of
beliefs as nothing but perfomative speech acts that subject the speaker
to making a commitment in standing by the assertion in proportional to
its degree, such as willingness to bet, then an epistemic judgment is
considered as rational so long as the agent's act in accordance with it in
the future. This is what Reflection is supposed to codify.

From a Peircean perspective, however, this is an incomplete picture of
our epistemic practice. The matter can be divided into two different
points. First, ampliative reasoning, i.e., extrapolation beyond what our
evidence says, can be justified in certain contexts. As is well known,
Peirce is responsible for distinction between abduction, deduction and
induction. Following Issac Levi, we can understand abduction, deduction,
and induction broadly not only as distinct types of \emph{inferences},
and but also different \emph{tasks} involved in our practice of
inquiry.\footnote{Isaac Levi, ``11 Beware of Syllogism: Statistical
  Reasoning and Conjecturing According to Peirce,'' in \emph{The
  Cambridge Companion to Peirce}, ed. C. J. Misak (Cambridge University
  Press, 2004), 281.} Abduction concerns how the question of the inquiry
is \emph{framed}, such as choosing the hypothesis for testing. Once a
framework for inquiry has been chosen, it is the task of deduction to
tease out the necessary consequences, such as sub-hypotheses, so that
the criteria for empirical adequacy are clear. \emph{Induction} then
takes place by testing the hypothesis against the deliverance of
experience.

What I shall argue below is that Reflection and voluntarism should be
understood in the context of \emph{abduction}. My contention is that the
seemingly perplexing combination of the permissive rationality of
voluntarism and the normative constraint of Reflection makes sense as
part of the exploratory stage of inquiry, in which we have to make
decisions about our experimental commitment \emph{before} having any
evidence at hand. I must, however, begin by addressing the thorny issue
of inference to the best explanation(IBE). This is essential, because
(1) contemporary philosophers of science often use abduction as a
synonymy of IBE, and (2) van Fraassen is well-known for arguing against
any attempt to incorporate IBE in the context of probabilistic
reasoning. A critical discussion of these issues will not only clarify
the sense of abduction needed for my position, but also dislodge in
advance van Fraassen's criticism.

\hypertarget{van-fraassens-anti-abductivism}{%
\subsection{Van Fraassen's
Anti-Abductivism}\label{van-fraassens-anti-abductivism}}

For the sake of brevity, let us call \emph{explanationism} the position
that accepts  inference to the best explanation(IBE) as an indispensable
rule of \emph{inductive} inference. In its most naive form, IBE says
that we should infer that the hypothesis that best \emph{explains} the
evidence we have is the one we should \emph{accept}. Van Fraassen is
well-known for arguing against IBE in this naive form. In
its most powerful form---a view that van Fraassen does ascribe
to some philosophers---IBE can be construed as a solution to Hume's
problem of induction, which holds that there is no independent
justification for extrapolating inductively beyond the evidence we have.
IBE gets us out of this problems by giving justificatory force to
explanatory virtues, so that the best explanation is the one we
\emph{should} accept. Van Fraassen attacks this position relentlessly.
One often cited argument of his is that we never pick the best
explanation \emph{simplicter}, but the best \emph{out of the
explanations available to us}. Van Fraassen argues this is a horrible
justification for a belief, since for some reason we might only have
horrible explanations available to us, so `our selection may well be the
best of a bad lot.' \footnote{\cite{bvfsi}, 143}

Van Fraassen suggests that, in light of the criticisms against naive PIBE, the strongest recourse available the
supporters of IBE is \emph{entrenchment}, which amounts to the
repackaging IBE into a rule that works well with Bayesianism. The more
plausible way to do this, according to van Fraassen, is to give
explanatory virtues a place in the revision of belief in light of new
evidence:

\begin{quote}
Combining the ideas of personal probability and living by rules, the new
rule of IBE would be a recipe for adjusting our personal probabilities
while respecting the \emph{explanatory} (as well as predictive) success
of hypotheses.\footnote{\cite{bvflaws}, 149.}
\end{quote}

Let's call this new rule `probabilistic inference to the best
explanation' (PIBE), which entitles us to raise the probability of the
best explanation. For instance, consider Peter Lipton's description of his position in \emph{Inference to the Best Explanaton}:

\begin{quote}
{[}My{]} version {[}of IBE{]} claims that the explanation that would, if
true, provide the deepest understanding is the explanation that is
likeliest to be true. Such an account suggests a really lovely
explanation of our inferential practice itself, one that links the
search for truth and the search for understanding in a fundamental way.\footnote{\cite{lipton},63.}
\end{quote}

Van Fraassen, however, argues that this cannot do. To begin, if IBE is
to be harmonized with Bayesianism, it must not clash the Bayesian
procedure of belief revision, i.e., conditionalization, but van Fraassen
argues that PIBE is inconsistent with the Bayesian standard
of rationality. The problem again is Bayesianism's allergy to ampliative
reasoning: PIBE is ampliative, since explanatory virtues goes beyond
what is logically implied by our evidence, so it is incompatible with
the explicative nature of Bayes' theorem---the posterior
probability is nothing but an arithmetic consequence of conditional
probability. Since PIBE is the rule that confers
`bonus' probability to a belief based on its explanatory virtue, this bonus  conflicts with Bayesianism.

Van Fraassen uses a Dutch book argument against explanationism. The gist
of the argument is that an explanatioinst will violate
conditionalization when they raise the probability of the best
explanation. This leads to a guaranteed loss when the bookie offers bets
based on the explanationist's prior belief, and then based on the
explanationist's belief after \emph{both} conditionalization and PIBE. A
simplified version of his argument is presented in the next section.
Readers uninterested in the technical details can skip it without loss
of continuity.

\hypertarget{van-fraassens-dutch-book-argument-against-pibe}{%
\subsection{Van Fraassen's Dutch book argument against
PIBE}\label{van-fraassens-dutch-book-argument-against-pibe}}

Suppose we are interested in the bias of a certain coin, \(\theta\),
which indicates the probability of the coin landing on heads. Suppose we
know that there are 3 equally probable hypotheses: (A) \(\theta = 0.9\),
(B) \(\theta = 0.5\), and (C) \(\theta = 0.1\). Suppose our evidence
gathering process is described as follows: \(X_i = 1\) denotes `the coin
has landed on heads on the \(i\) toss' and \(X_i = 0\) otherwise.
Suppose we have toss the coin 4 times, and they all landed on heads. So
the evidence \(E\) is \(\sum_{i=0}^4 X_i = 4\). The marginal probability
for \(E\) is:

\[P(E) = P(A)P(E|A)+P(B)P(E|B)+P(C)P(E|C) = 0.24\]

Using Bayes' theorem, the posterior probabilities are:
\(P(A|E) = 0.9129\), \(P(B|E) = 0.0869\), and \(P(C|E) = 0.0001\). So
far so good---4 consecutive heads favors the hypothesis that the coin is
bias toward heads, which is what conditionalization is showing us. Where
does PIBE comes in, then? Van Fraassen asserts that an argument from
PIBE would be as follows: out of the three hypotheses, \(A\) best
\emph{explains} why we see nothing but heads: it's because it's highly
biased. So what PIBE should do is to recommend the redistribution of the
probabilities so that \(P(A)\) would be even higher. Suppose we raise
\(P(A)\) to \(0.999\). This amounts to giving the best explanation a
bonus of \(0.086\) in probability. To accommodate this, we can lower the
probabilities of the other hypotheses accordingly. For instance:
\(P(A) = 0.999\), \(P(B) = 0.00086\), and \(P(C) = 0.00014\). So we have
extrapolated ampliatively beyond what the evidence tells us by using
PIBE.

This line of reasoning, however, flies in the face of the Bayesian
notion of \emph{coherence}, since it renders one subject toa set of bets
that ensures whoever takes these bets a loss. Imagine that we are back
at the beginning before we tossed 4 heads. Before tossing the coin for
four times, we were offered the following set of bets. Let \(E\) again
be `the coin is tossed 4 times and they are all heads' and \(H\) be the
\(X_5=1\), that is, `the fifth toss turns up heads'.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \$10,000 if \(E\) and \(\neg H\).
\item
  \$1300 if \(\neg E\).
\item
  \$300 if \(E\).
\end{enumerate}

Now, we can calculate the values of these bets based on our prior
probabilities:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Bet 1: \((10000) \frac{0.8^4(0.2) + 0.5^5 + 0.2^4(0.8)}{3} = 323.16\)
\item
  Bet 2: \((1300) (1-0.158) = 988.56\)
\item
  Bet 3: \((300) 0.158 = 71.87\)
\end{enumerate}

So these bets would be worth \$1383.6 in total. Suppose we bought these
bets for exactly that much from a bookie, who then proceeded to toss the
coin for 4 times. Either \(E\) is true or it is false. Suppose it's
false---at least one toss landed on tails. In this case, we would have
won bet 2 but lost 1 and 3. We would receive \$1300 but this would still
lead to a total loss of \(-1383.6+1300=-83.6\).

On the other hand, suppose \(E\)---all tosses turned up heads. We would
receive \$300 per bet 3, and now bet 1 would depend entirely on the
fifth toss. Now, van Fraassen asks, what should our degree of belief for
\(\neg H\), that the fifth toss will land on tails? Recall that we have
used PIBE to give a bonus to the most explanatory hypothesis, \(A\),
which effectively has raised the marginal probability of \(H\) to
\(0.9\). At this point, bet 1 is now worth
\((10000)P(\neg H) = (10000)0.1 = 1000\). Suppose the bookie offers us
exactly \$1000 to buy this bet back. We would regard it as fair and
accept his offer. In this scenario, we end up with
\(-1383.6+300+1000 = -83.6\)---we incur exactly the same loss as we
would if \(E\) were false.

\hypertarget{abduction-predesignation-and-reflection}{%
\subsection{Abduction, Predesignation, and
Reflection}\label{abduction-predesignation-and-reflection}}

Van Fraassen's argument is often misunderstood. When explanationists
cite van Fraassen's anti-IBE argument, it may sound as though van
Fraassen takes Bayesianism as the correct position by fiat, so that any
position that contradicts it is \emph{de facto} an inviable one. Indeed,
this is how many explanationists read him. Take Lipton for instance:

\begin{quote}
In its simplest form, the threatening argument says that Bayesianism is
right, so Inference to the Best Explanation must be wrong.\footnote{Peter
  Lipton, \emph{Inference to the Best Explanation} (Routledge/Taylor;
  Francis Group, 2004), 104.}
\end{quote}

But given our discussion of voluntarism, this assessment of the
situation is not quite right, at least in the original context of the
argument. The voluntarist argument is not that it is irrational to use
conditionalization or IBE, but that (1) they are not rationally
compelling in and of themselves, and (2) repacking IBE as some
probabilistic rule is inconsistent with Bayesian conditionalization.

Many explanationists, including Lipon, who misread van Fraassen's
argument attempts to challenge van Fraassen's negative argument heads
on, by defending that both conditionalization and PIBE are rationally
compelling. By taking this approach, explanationists have to argue for
the legitimacy of PIBE within the stringent requirement of Bayesianism.
To do so, they must give an account of how explanation can influence
probabilities without subjecting oneself to a Dutchbook Argument. The
strategy here is a mixture of neutralizing PIBE so that it will not get
in the way of conditionalization, and providing incentives for Bayesians
to adopt it by amplifying or emphasizing PIBE in areas where
conditionalization comes up short. The result of this approach is often
an unsavory stew, since it has to dance around neutralizing and
strengthening PIBE without either trivializing it or over-promising what
IBE can do.

Alternatively, we could take the path of less resistance: instead of
hamstringing explanatory reasoning in order to accommodate the stringent
requirement of Bayesian rationality, we should exploit the liberating
nature of voluntarism. Like explanationist, I think that explanatory
reasoning is an indispensable element in our probabilistic and
statistical reasoning, but I also agree with van Fraassen that PIBE
cannot be made consistent with conditionalization. I advocate a largely
Peircean position that can accomplish this.

In Peirce's ideas we can find a view that agrees with explanationism
that abduction is indispensable to induction but also with van
Fraassen's voluntarist point that the acceptance of a hypothesis have
practical repercussions on the inquirer's future behaviors. The crucial
point is that making an epistemic commitment is not ``a brute exercise
of strength''---instead such a commitment can satisfy the aim of inquiry
only if it is situated with framework that allows \emph{vindication} if
the hypothesis withstands the tribunal of experience, and
\emph{correction} if it fails.

The permissiveness of voluntaristic conception of rationality is
characteristic of ampliative reasoning that occur with in the context of
Peirce's conception of abduction. At this stage of inquiry, different
hypotheses can be introduced to the logical space of reasons for
non-evidential reasons, hence abduction is ``the first starting of a
hypothesis and the entertaining of it.''\footnote{\cite{CP}, 6.525.} For
instance, hypothesis that in any way explain the phenomenon under
investigation is permissible. In his early years, Peirce uses the
following syllogistic schema to illustrate one example of abduction:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The surprising fact, C, is observed;
\item
  But if A were true, C would be a matter of course.
\item
  Hence, there is reason to suspect that A is true.\footnote{\cite{CP},
    5.189.}
\end{enumerate}

While Peirce, at least in his later years, does not think that this schema encompasses all possible forms of abductions, it is nevertheless a helpful starting point: \(C\) is the observed \emph{fact} that calls for a
hypothesis that would, in Peirce's words, \emph{rationalize}
it.\footnote{\cite{essentialpeirce2}, 107.}
Peirce sometimes refers to \(A\) as an \emph{abductive suggestion} that
follows the perception of the surprising fact.\footnote{\cite{essentialpeirce2}, 227.}
They are \emph{possible} accounts for the phenomenon observed, and are
not presented as true proposition, but hypotheses that we may accept
provisionally for the sake of further testing. Thus, in the context of
abduction, ampliative inference is justified, because the goal here is
the introduction of hypotheses, without which neither induction nor
deduction can proceed. Hence Peirce holds that the role of abduction is
paramount to the growth of knowledge, as it is ``the only logical
operation which introduces new ideas.''\footnote{\cite{essentialpeirce2}, 216.} This is
why explanatoriness is a relevant factor in abduction: During abduction,
explanatory virtue is clearly a relevant consideration, for the
construction of a framework pertains to the choice of a hypothesis to be
tested, and how much the hypothesis, \emph{if true}, explains would
provide ground for making the hypothesis a genuine contender.

We see a crucial difference in the Peircean's conception of abduction
and the explanationist conception. Peirce clearly sees no conceptual
connection between a hypothesis's explanatoriness and its probability.
Abductive reasoning is a creative but risky process:

\begin{quote}
The abductive suggestion comes to us like a flash. It is an act of
insight, although of extremely infallible insight.\footnote{Peirce, 227.}
\end{quote}

\begin{quote}
\ldots{}abduction is, after all, nothing but guessing.\footnote{Peirce,
  \emph{Collected Papers of Charles Sanders Peirce}, 1931, 7.219.}
\end{quote}

Therefore, in the abductive context, an agent can accept a hypothesis
that is not only improbable but also with low explanatory values, if the
hypothesis is \emph{informative}. For instance, we may choose to accept
an improbable hypothesis provisionally if we know, through deduction,
that the confirmation or rejection of the hypothesis will necessarily
rule out many others. Peirce also suggests that a hypothesis may be
adopted for pure economical reasons. So, unlike the explanationists,
Peirce sees no reason to think that an explanation that explains is one
that is also probable. Explanatory virtue is but one of many relevant
factors in abduction.

Peirce's view on abductive rationality, then, \emph{is} voluntarism:
epistemic judgments made in the abductive context is not justified by
probability or truth, but the deliberate adherence to the commitments
implied by the judgment asserted. This is made clearly by Peirce here:

\begin{quote}
An Abduction is a method of forming a general prediction without any
positive assurance that it will succeed either in the special case or
usually, its justification being that it is the only possible hope of
regulating our future conduct rationally.\footnote{Peirce, 2.270.}
\end{quote}

As discussed, the notion of deliberate conduct is central to Peirce
pragmatism, and to understand the role it plays in relation to
abduction, we must also understand Peirce's statistical understanding of
inquiry.

As Peirce sees it, the validity of inductive reasoning is strictly
regulated by the statistical structure deductively by the commitments
she makes in the abductive context. This means that the epistemic
judgments made during abduction cannot be changed during the inductive
context, otherwise the inference would be invalidated altogether. This
can be seen as a requirement to hold an experimental version Reflection:
I have to stand by my decision to provisionally accept the abduced
hypothesis, before my obligation is satisfactory discharged at the very
end of the experiment. I cannot, for instance, rationally change my
hypothesis to fit the data better in the middle of the data-gathering
process. Peirce codifies this requirement as \emph{the rule of
predesignation}, which he calls a necessary guiding principle of
induction.\footnote{\cite{essentialpeirce2}, 48.}

The idea is that the inquirer's commitments, intentions, and judgments
all make contribution to the context in which the inductive inference is
made. This is why the decisions the agent makes during the abductive
context constitute the experimental framework for the testing of the
chosen hypothesis, and the rule of predeisgnation imposes a rational
constraint on the inquirer's opinions during the inductive context. In
particular, the decision the agent makes during abductive phase requires
the agent to stand by these commitments during the inductive stage of
the inquiry. This is how Peirce explains it:

\begin{quote}
If in sampling any class, say the M's, we first decide what the
character P is for which we propose to sample that class, and also how
many instances we propose to draw, \emph{our inference is really made
before these latter are drawn}, that the proportion of P's in the whole
class is probably about the same as among the instances that are to be
drawn, and the only thing we have to do is to draw them and observe the
ratio.\footnote{\cite{probableinference}, 434.}
\end{quote}

In other words, making statistical inference presupposes a commitment to
the assumptions implied by what it means to carry out random sampling.
In particular, the responsibility must be taken up prior to the sampling
itself, by committing into the stipulations in the experimental setup,
such as the statistical hypothesis to be tested and the length of the
trial. Hence, Peirce says that once those details have been settled, the
inquirer must take the responsibility of carrying it out exactly as she
described; otherwise, the inference is illegitimate.

\begin{quote}
But suppose we were to draw our inferences without the predesignation of
the character P; then we might in every case find some recondite
character in which those instances would all agree. That, by the
exercise of sufficient ingenuity, we should be sure to be able to do
this, even if not a single other object of the class M possessed that
character, is a matter of demonstration.
\end{quote}

Using van Fraassen's voluntaristic terminology, such an action is
\emph{self-sabotaging}, because if the length of the trial is unfixed,
the investigator can keep on sampling until they find a sample that
supports her hypothesis. The sampling here would not be random, and the
inference would not be valid. After the investigator has made her
experimental commitments clear, as Peirce says, ``the only thing we have
to do is to draw them and observe the ratio.'' This is why Peirce
insists that rationality \emph{requires} what he calls deliberate
conduct---I must stand by the decisions I made in abduction, which is to
faithfully carry out the sampling process dictated by the probability
model, and accept or reject the hypothesis based on the criteria I
specified. 

\section{Conclusion}

This serves as an important transition to the next chapter. Peirce's Pragmatic Maxim and tripartite classification of different contexts of inquiry provide a unified way of understanding how epistemic commitments figure into our probabilistic inferences and experimental procedures. Making inductive inferences based on experimental procedures \emph{presupposes} that we can rely on the experiment to behave deliberately in accord to the setup of the experiment promised at the outset. If the experiment is stopped earlier or later than promised, the character of the inference could be drastically change. How inferences could be dependent on whether or not these practical commitments are satisfied is the focus of the coming chapter. The conclusion I put forth in the this chapter, then, leaves open the question of how exactly deliberative elements can be criticized from a Bayesian perspective. This will be addressed in next chapter.

