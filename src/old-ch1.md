
## Operationalist Pragmatism

Discussions of the Pragmatic Maxim often begin with Peirce's "How to Make our Ideas Clear", as it contains perhaps the most well-known articulation of the principle:

> Consider what effects, that might conceivably have practical bearings, we conceive the object of our conception to have. Then, our conception of these effects is the whole of our conception of the object. [@makeideasclear, p.266]

The Pragmatic Maxim, even on a limited reading, seems to suggest that the meaning of a word is tied to some publicly perceivable phenomenon. An *operationalist* reading of the maxim, in particular, holds that the "practical bearings" mentioned above refers the *causal effects* of the object denoted by the word.[@whatpragwas 43] This operationalism is motivated by a commitment to define terms in a way that is conducive to scientific inquiry. Many ideas handed down to us by tradition do not naturally admit empirical investigation. Thus, we should clarify them so that questions about them can be resolved by appealing to evidence. [@hoover1994 292] The operationalist reading of the Pragmatic Maxim emphasizes on Peirce's view on how we should analyze our ideas in service of scientific endeavors. Such an attitude is easily found in Peirce's early epistemological writing, such as "How to Make our Ideas Clear," in which Peirce concerns himself with a notion of conceptual clarity that is free of Cartesian baggages. A well-known example is Peirce's application of the Pragmatic Maxim on the concept of hardness: something is hard if and only if it will not be scratched easily. 

### Pragmatism and Verificationism



<!-- That is, our conception of an object is identified with the effects *it has caused.* So if a concept refers to something that just happens to have never caused an effect, even thought it *would* have caused an effect under other circumstances, then it has no meaning.
 -->
<!-- 
For instance, the pragmatic maxim in "How to Make Our Ideas Clear" is open to be interpreted as expressing a view that that our conception of an object is identified with the effects *it has caused.* So if a concept refers to something that just happens to have never caused an effect, even thought it *would* have caused an effect under other circumstances, then it has no meaning. It is possible to interpret Peirce's diamond example as saying this: it is meaningless to say that the diamond is "hard" if throughout its existence there has never been an attempt for it to be scratched.  -->


The operationalist reading of the Pragmatic Maxim may sounds suspiciously like the logical positivists' verificationism, which says something along the lines of words owe their meanings entirely to verifiable sense experience. This is partly bolstered by Perice's remark that there is "absolutely no difference between a hard thing and a soft thing so long as they are not brought to the test."[@makeideasclear] In effect, Peirce is taken as expressing a view that that our conception of an object is identified with the effects *it has caused.* So if a concept refers to something that just happens to have never caused an effect, even thought it *would* have caused an effect under other circumstances, then it has no meaning. It is possible to interpret Peirce's diamond example as saying this: it is meaningless to say that the diamond is "hard" if throughout its existence there has never been an attempt for it to be scratched. 


This is how Ayer, for instance, reads Peirce. Ayer takes Peirce's view to be essentially verificationism, except, instead defining a word by its verifiable subjective experience, it reduces the meaning of a word to "listing the facts to which the word applies" [@ayer-origin, 51]. Peirce's impatience with unproductive philosophical disputes is, without a doubt, an attitude with which a logical positivist like Ayer sympathizes. Ayer clearly identifies the operationalism in Peirce's thought. I reproduce the quotes below in full because Ayer gets Peirce so right, yet, as we will see, so wrong at the same time:

> It should by now be clear that what we are being offered here is a hard-headed version of the theory of operationalism... It should be clear also that the reason why I call Peirce's version of the theory hard-headed is that it stipulates that the basis to which theoretical statements are to be reduced consists not of statements referring to what is observable, but of statements referring to what is actually observed... A theory of this kind has obvious attractions. It puts all the cards on the table and thereby frees us from such tiresome complaints as: 'We know what the effects of electricity are, but we do not know what electricity is'. Electricity is what electricity does. With everything brought into the open, we are spared any nonsense about occult qualities. The theory forbids us to search for the current in the wire, or the leprechaun in the watch. In short, it allows no truck with metaphysics. Its standpoint is very closely akin to that which was later to be adopted by the logical positivists. Peirce's pragmatic maxim is indeed identical, for all practical purposes, with the physicalist interpretation of the verification principle. [@ayer-origin, 55]

Eager to conscript Peirce into his own camp, Ayer attributes to him a very strong skepticism about theoretical entities. This reading, however, misreads the Pragmatic Maxim: it does not say a concept is reduced to its actual effects; instead, it states that concepts are delineated by the effects "that might *conceivably* have practical bearing, we *conceive* the object of conception to have". The distinction between the two is not verbal. Peirce takes the full understanding of an object - insofar as all doubts about it is eliminated, to require the knowledge of how just how it behaved but also how it would behave in counterfactual situations. 

In other words, Peirce's account is dispositional. For instance, Peirce says that the point of the diamond example is not a metaphysical reduction of the property of being hard into nothing but a list facts pertaining the diamond being scratched, but an epistemological point about how properties such as hardness can be probed through learning it *would* behave under all conceivable scenario, including counterfactual ones. [@CP, 5.453] Only then we are entitled to say that we have thoroughly learned what the property of hardness is. Most important, these facts and counterfacts are evidence *for* the existence of abstract and theoretical entities, and not a reduction of them.


I belabor the pragmatist v.s. positivist distinction for a specific reason: Peirce's analysis of belief is also subtly different than behavioralism about belief, which says that belief is nothing but its behavior. This is especially important to keep in mind, when we consider Peirce's influence on Ramsey's view later. Like behavioralism, Peirce's operationalist account of belief can be seen as a scientific reconstruction of its pre-theoretical notion; however, even on an operationalist reading, Peirce does not buy into reductionism. To begin, Peirce recognizes and does not deny the subjective aspects of belief: it is something that "we are aware of" and that "appeases the irritation of doubt". However, in accordance to the maxim, beliefs must be differentiated in terms of their practical consequence.  That is, beliefs should be seen as something that causes predictable behavior under suitable circumstances. To believe that a certain chemical is poisonous, for instance, is to have a disinclination to drink it if the chemical is believed to be present. 

Peirce's operationalism is especially important in "How to Make our Ideas Clear", as he concerns himself with giving an account of his belief/doubt model of epistemology, using a methodology in accordance to the Pragmatic Maxim. In order to avoid the counterproductive connotations of "belief" and "doubt", Peirce endeavors to define them in commonsensical yet empirically available terms: doubt is characterized as the cause of hesitation, inaction, and indecision. Belief is characterized as a stable disposition: 'the establishment in our nature of a rule of action' [@makeideasclear 263]. 
<!-- 
The distinction between belief and doubt above is an application of the Pragmatic Maxim on the terms themselves, that is, explicating what belief is, in contrast to doubt. But Perice is also interested in using 

The goal X
As
The upshot is that belief 'involves 
 -->

We will return to Peirce's conception of belief in our discussion of his inferentialism, but in the context of operationalism, the crucial point is that the Pragmatic Maxim suggests that belief can be analyzed as a disposition, and different beliefs can be distinguished in terms of the behavioral differences they cause. This is the crucial insight Ramsey borrows from Peirce in his theory of subjective probability. 


### Peirce on the Measurement of Degrees of Belief

Peirce has written extensively on probability. When we put together that fact plus his operationalism, it would seem that he would take take the idea of measuring degrees of belief by virtue of some behavioral criteria, a procedure accepted by many Bayesians. The truth of the matter is a bit more delicate, because, while Peirce certainly has a lot to say about degrees of belief, many of his remarks are lumped together with his criticism of subjective probability. 

To begin, the Proto-Bayesianism in Peirce's time, called Conceptualism, was heavily influenced by Laplace's view, especially the acceptance of the so-called Principle of Indifference, which says roughly that complete ignorance should be modeled as a uniform distribution over all hypotheses. In a typical case of estimating a unfamiliar coin's probability of heads, this would mean that the expected value is $0.5$. Peirce vehemently rejects this principle, as he argues that in many cases, especially when the number of possible outcomes is ambiguous, using the principle will lead to contradictions. A simple example would be determining the probability of an unknown object, for example, a marble, having a certain color, say, red.  Suppose I have no information about this marble, so I have no reason to think the marble is red or not.^[Assume that the cover of the book has only one color.] Following the principle, it would seem that $P(R) = P(\neg R) = 0.5$. However, we are led to contradictions when we asks if the book is yellow, black, etc.; because, using the same reasoning, we would say $P(Y) = P(\neg Y) = P(B) = P(\neg B) = 0.5$. The contradiction is that these are mutually exclusive propositions, so axioms of probability say that their sum cannot go beyond $1$. As we will see in a later section, Keynes has some important things to say about this, but for now it is sufficient to note that Peirce appeals to examples like this when criticizing the principle. 

Furthermore, Conceptualists, like many Bayesians now, hold that degrees of belief only admit precise numerical values. That is, all beliefs, on principle, can be captured by *one* probability distribution function that assigns a single value to each belief. Peirce's argument against it is pragmatic: there is a behavioral difference between betting on a fair coin and a unfamiliar coin. For the former you should know exactly how much to bet, in the latter case you should simply refrain from betting. The Conceptualist model, however, cannot make sense of this, since both entail the degree of belief of $0.5$. Nowadays this is usually known as the *Ellsberg's Paradox*.[@ellsberg]

It is entirely possible that a model of degrees of belief that does not rely on the Principle of Indifference and admit imprecise probability. That's not a question we need to settle here.  I explicitly state Perice's disagreement with Conceptualists, because his ideas about defining degrees of belief, as suggestive as they are, should not be interpreted as a part of Peirce's established view.^[Some interpreters *do* attribute to Peirce such a view: see @msak2016peirce 30-31] Peirce's own view is best described in our own term as "hypothetical frequentism," which is a *propensity* view of probability that makes a modal interpretation of the limiting relative frequency.[@propensitiesandpragmatism] Hypothetical frequentism is definitely not a fashionable view in philosophy, but variants of the view can be found in early van Fraassen's modal frequency account and later Lewis's best system interpretation of probability.[@bvfsi ch6 sec4][@debugged][@againsthf]

In any case, as a transition to the next section, I will discuss Peirce's idea about how to operationalize degrees of belief. If different degrees of belief, as required by the pragmatic maxim, are to have any meaning, they must have practical bearings. This is one of Peirce's criticisms of Conceptualism:

> Conceptualists have not undertaken to say what is meant by "degree of credence." They would probably pronounce it indefinable and indescribable. Their philosophy deals much with the indefinable and indescribable.[@vennlogicreview, 99]


In a critical discussion of Conceptualism, Peirce suggests that degrees of belief could be defined as the subjective intensity of a belief. Peirce's proposal is based the "Fechner's psycho-physical law," which states "the intensity of any sensation is proportional to the logarithm of the external force which produces it" [@probabilityofinduction, 293].  Since this law requires a reference to some external facts, Peirce preserves an objective element in his account of degrees of belief. This proposal to tie degrees of belief to an external event is consistent with Peirce's operationalism in his pragmatic conception of belief, but there is one interesting difference: when dealing with full beliefs, Peirce emphasizes on the practical effect of having a belief, while for partial belief the direction is reversed.

To explicate this external force that produces degrees of belief in an agent, Peirce introduces the idea of "chance," which is what we would call odds - "the ratio of favorable to unfavorable cases".[@probabilityofinduction, 293] Peirce then claims that "the chance of an event has an intimate connection with the degree of our belief in it" [@probabilityofinduction, 293]. What Peirce has in mind is that degrees of belief can be measured in terms of an intensity based on Fechner's law above, by taking the log of the odds as the external force:


>Belief is certainly something more than a mere feeling; yet there is a feeling of believing, and this feeling does and ought to vary with the chance of the thing believed, as deduced from all the arguments. Any quantity which varies with the chance might, therefore, it would seem, serve as a thermometer for the proper intensity of belief. [@probabilityofinduction, 294]

Peirce's suggestion is that degrees of belief about an event should track odds of events. Take some proposition $A$ and its probability $p$; let us define the intensity of $A$ as:

$$Int(A) = log(\frac{p}{1-p})$$ 

Why does Peirce choose log-odds to measure the intensity of beliefs, instead of just probability? This can be seen as another application of the Pragmatic Maxim by pinpointing an empirical anchor for degrees of belief. To begin, there is mismatch between probability and intensity of feeling: if to regard a proposition $A$ with indifference is, as Conceptualists claim, to assign $P(A) = P(\neg A) = 0.5$, then, assuming indifference implies the total lack of intensity, $Int(A) = 0$ when $P(A) = 0.5$ and not when $P(A)$ is $0$. This works out mathematically, since

$$Int(A) = log(\frac{0.5}{1-0.5}) = 0$$ 

Peirce also derives an evidential principle from this definition: given a prior odd of 1 for $A$ and evidence $E$, the posterior odd for $A$, $\frac{P(A|E)}{P(\neg A |E)}$ can be algebraically reformulated as the so-called likelihood ratio: $\frac{P(E|A)}{P( E| \neg A)}$. After taking the log of the ratio as Peirce suggested, we can find the balance of the evidence by calculating $log(P(E|A)) - log(P(E|\neg A))$. A positive value means the evidence is in favor of A and negative against it. 

Some modern Bayesians were so impressed with Peirce's account that they incorporated Peirce's ideas into their own frameworks.[@Fitelson2001-FITABA] But from an argumentative perspective, the purpose of Peirce's proposal is to make *Reductio Ad Absurdum* argument against Conceptualism, since his point is that if we assume this account, then an agent should have the same intensity of feeling for a proposition with a probability of $0.5$ and one to which the agent does not know enough to assign a probability. 

However, while it is clear that Peirce does not think this account of degrees of belief can be a normative theory of rational thinking, we have some evidence to the idea that he accepts it as a good operationalized definition to probe the psychology of human behavior. This is what he carried out in his paper "On Small Differences of Sensation"[@smalldifferences]. In there, he and J. Jastrow carried out an experimental to discredit the theory of "least perceptible difference", that is, there is a point at which human beings fail to distinguish the slight difference in a property. They posit that if this hypothesis were true, the probability of a subject being able to correctly distinguish a difference that is smaller than the least perceptible difference should be $0.5$, since they would just be guessing. 

The experiment involves testing the subject's sense of pressure by presenting to them two slightly different weight, and then they would be asked to report which they think is heavier. The subject's degrees of confidence $m$ is then probed by asking them to rate it according to the following scheme:

- 0 denoted absence of any preference for on answer over its opposite, so that it seemed nonsensical to answer at all.
- 1 denoted a distinct leaning to one alternative.
- 2 denoted some little confidence of being right.
- 3 denoted as strong a confidence as one would have about such sensations.[@smalldifferences 124]

Peirce and Jastrow then suggest that degrees of confidence can be modeled using Peirce's definition of degrees of belief:

$$ m = c log\frac{p}{1-p} $$

Where $m$ is the subjective degree of confidence on the 0-4 scale, $p$ is the *objective* probability of the subject being right. $c$ is a normalizing constant they call "index of confidence". The historian of statistics Stephen M. Stigler notes that, even though Peirce is a frequentist, "his work here shows he was also one of the first individual (perhaps the very first) to experimentally elicit subjective or personal probabilities, determining that these probabilities varied approximately linearly with the log odds."[@mathstatearly 248]



To reiterate, my purpose in this section is to make explicit the connection between the Pragmatic Maxim and the measurement of degrees of belief. The *operationalist* reading of the Maxim suggests that degrees of belief could be explicated in terms of empirically available phenomenon. While Peirce does not believe that probability should be understood as degrees of belief, he nevertheless utilizes his operationalism to carry out a descriptive study of the psychology of belief. Frank P. Ramsey, to whom we shall now turn, is influenced by Peirce's operationalism and we will see how his theory of subjective theory can be seen as a response to Peirce.


## Ramsey's Operationalism and Keynesian Logicism


Ramsey's "Truth and Probability" contains his to answer to the question: what are degrees of belief? His answer is strikingly Peircean: a belief is a disposition to act in a certain way under some conditions, and the degree of a belief is "the extent to which we are prepared to act on it".[@ramsey 170] In this section, I will discuss and examine Ramsey's operationalist conception of subjective probability in order to provide a proper contrast to the *inferentialist* view presented in chapter 4.

Some context: Ramsey was responding to the answer to the same question given by John M. Keynes, who argues that the degree of belief is a logical relation between a proposition and the set of propositions that support it. Moreover, this relation belongs to the same conceptual category as the entailment relation between the premises and conclusion in a deductive argument.[@keynes 57] The difference here is one of degree: in a derivation in deductive logic, the set of premises fully entails its conclusion. In probabilistic reasoning, the set of premises partially entail its conclusion, so in this view a probability is conceived as the degree of a partial entailment, that is, the degree to which the premises justify the conclusion.[@keynes 30]

However, Keynes' view has some philosophical baggage. He holds that knowledge about these logical relations are acquired through what Bertrand Russell calls "direct acquaintance".[@keynes 11-12] This implies finding out what the right degree of belief between two propositions is like perceiving what the color yellow is like. Ramsey responds to Keynes's view by rejecting the conception of degree of belief as perceptible logical relations:

>...there really do not seem to be any such things as the probability relations [Keynes] describes. He supposes that, at any rate in certain cases, they can be perceived; but speaking for myself I feel confident that this is not true. I do not perceive them, and if I am to be persuaded that they exist it must be by argument; moreover I shrewdly suspect that others do not perceive them either, because they are able to come to so very little agreement as to which of them relates any two given propositions.

It might seem that Ramsey is simply contradicting Keynes' view, without offering an argument.^[This is how Gillies reads this argument. He says that "This is an interesting case of an argument which gains in strength from the nature of the person who proposes it. Had a less distinguished logician than Ramsey objected that he was unable to perceive any logical relations of probability, Keynes might have replied that this was merely a sign of logical incompetence, or logical blindness."] Another way to interpret Ramsey's claim is that a productive notion of degrees of belief should not rely on private and subjective entities like intuition. Hence he writes

>The subject of our inquiry is the logic of partial belief, and I do not think we can carry it far unless we have at least an approximate notion of what partial belief is, and how, if at all, it can be measured... [A partial belief] has no precise meaning unless we specify more exactly how it is to be measured.

Ramsey's emphasis on the precise measurement of degrees of belief signifies his operationalist attitude that we have seen in Peirce. Following Peirce, then, Ramsey proposes degrees of belief ought to be defined in terms of its public manifestation, i.e., how it shapes the behavior of the agent. Ramsey's criticism to Keynes about relying on private entities is also strikingly analogous to Peirce's criticism to conceptualists. Further, Ramsey sees Peirce's counterfactual operationalism as a crucial piece of the puzzle, since it is able to dislodge the criticism of any behavioral account of belief. The argument is that many beliefs do not cause any action, so any behavioral definition of belief is doomed to fail. Ramsey dismisses these criticism as being "beside the mark, because it is not asserted that a belief is an idea which does actually lead to action, but one which would lead to action in suitable circumstances; just as a lump of arsenic is called poisonous not because it actually has killed or will kill anyone, but because it would kill anyone if he ate it."[@ramsey]

Unlike Peirce, however, Ramsey does not think that degrees of belief should be operationalized in terms of intensity of feeling. The first problem is that we can only know the agent's intensity of feeling through introspective reports, which can be unreliable since they "may be very variable from individual to individual."[@ramsey 171] The other is that not all strongly held beliefs have similarly strong feelings.[@ramsey 169] Based on historical data, my personal probability for the sun rising tomorrow is fairly high, but I have no strong feeling toward it.


<!-- Instead, Ramsey relies on Peirce's view on disposition to dislodge a criticism posed by Bertrand Russell in *Analysis of Mind*. Ramsey evidently reads Russell's criticism as the argument that behavioral account of belief must be wrong, since many beliefs do not cause any action; consequently, Ramsey dismisses Russell's concern as being "beside the mark, because it is not asserted that a belief is an idea which does actually lead to action, but one which would lead to action in suitable circumstances; just as a lump of arsenic is called poisonous not because it actually has killed or will kill anyone, but because it would kill anyone if he ate it."[@ramsey]  -->

Ramsey proposes that the proper empirical anchor can be found in the "old-established way of measuring a person's belief," which "is to propose a bet, and see what are the lowest odds which he will accept".[@ramsey 172] So if I am willing to bet at 2:1 that it will snow tomorrow, then my degree of this degree is $1/3$. However, Ramsey points out that using money is problematic because of its diminishing marginal utility. Instead, Ramsey proposes to use the more general notion of "goods or bads," - utility - for a framework of rationality. Ramsey's proposal is essentially what comes to known as the expected utility theory. The thought is that if belief is tied to action, and if actions are governed by the agent's desire to maximize utility, then we should be able to define degrees of belief based on the balance between how willing the agent is to act on p and the value that the agent bestows upon p. The intuition is, if a person is rational, her willingness to act on a belief should be tempered with the utility she thinks such an action would bring her, and vice versa. 

To give this idea precision, Ramsey puts forth eight axioms that, like von Neumann and Morgenstern's axioms of rationality, imply the existence of a utility function of an agent, which has properties such as continuity, transitivity of preference, etc. He then proposes a creative method of eliciting the agent's degrees of belief by appealing to their willingness to bet on certain propositions. The set of axioms is beyond the scope of our discussion. As I am not defending Ramsey's method, for now let us just assume such a function exist. 

Ramsey's proposal is that, to begin, we have to pragmatically determine the degree of belief for some "neutral" proposition $p$ about which the agent has no preference regarding its truth or falsity. That is, suppose we present the agent two states of the world, identical in all aspects *except* $p$ is true in one and false in another. If the agent does not care which world she belongs to, $p$ is a neutral proposition. 

Then, consider two events,$\alpha$ and $\beta$ the truths of which $do$ matter to the agent.^[Following Ramsey, Greek letters are used to denote value-laden outcomes.] In particular, suppose $\alpha$ refers to the outcome in which you receive $100 and in $\beta$ you receive nothing, so, given some reasonable assumptions, $\alpha$ is preferable to $\beta$. Ramsey's idea is that we can use $\alpha$ and $\beta$ to determine the agent's degree of belief of $p$. For example, say a fair die will be rolled and let $p$ be "an even number is rolled." Assuming the agent has no favorite number, for her $p$ would be a neutral proposition. 

We then offer the agent the following options:


1.  $\alpha$  if $p$, and $\beta$ if $\neg p$. (Receive $100 if an even number is rolled, and nothing otherwise. )
2.  $\alpha$  if $\neg p$, and $\beta$ if $p$ (Receive $100 if an odd number is rolled, and nothing otherwise.)

If, and only if, the agent is indifferent between the options, her degree of belief of $p$ is 1/2. 
<!-- 
### A Rough Outline of Ramsey's Elicitation Procedure



It seems like *a lot* of work just to ascertain the probability of 


 -->


## Indifference and Rational Degrees of Belief

How should probability constrain our beliefs? Can degrees of belief be rational? These *normative* questions have been conspicuously missing from our discussion so far. This, I think, is a natural consequence of the operationalist reading of the Pragmatic Maxim, that is, we are understanding "practical bearing" of a concept to be some descriptions of what the referent of the object would behave under different circumstances. As a result, we have been concerning ourselves with what sort of facts or things should serve as the empirical anchor for degrees of belief, such as intensity of feelings or willingness to bet.  In this section, I want to suggest that one of the shortcomings of the operationalist approach, which is highly *descriptive* in nature, is that it fails to address normative concerns of rationality. 

Ramsey's operationalized degrees of belief has to be understood against the background of Keynes' *rational* degrees of belief. To begin, Keynes' logical interpretation of probability has the advantage of providing a direct explanation on why probability is *normative*: we *should* reason in accordance to probability for the same reason that we should respect a deductive rule like _modus ponens_: the degrees of a person's partial belief should correspond to the degree to which the premises render the conclusion probable, whereas in a deductive proof, one has to accept the conclusion as necessarily true, were the premises true. Hence Keynes talks about probability not as something we can attribute to a proposition, or one's attitude of it, but a logical property of an argument.^[There is a technical consequence for this. If probability is a relation, it follows that it never makes sense to talk about the probability of an event without in relation to any other proposition, so for Keynes all probabilities are conditional probabilities.] As Frequentists often find little use for the idea of degrees of belief, it is often discussed in the context of subjective probability; however Keynes' rational degrees of belief are supposed to be objective relations that are part of the basic furniture of the world.

This is why the Principle of Indifference, mentioned above, is crucial to Keynes' notion of rational degrees of belief. Recall that, according to Peirce's operationalized definition, degrees of belief are degrees of intensities of feeling about the belief, so the Principle of Indifference is used as a guiding principle for translation: the psychological experience of indifference or ambivalence toward a proposition is to be translated as having equal degrees of belief toward it and its negation. As we have seen, Ramsey's approach can be seen as an extension of the same idea: instead of reports of feelings, we translate the agent's equal willingness to bet on two sets of propositions as being indifference.

If probability, according to Keynes, is not analyzable in terms of empirical features, but an irreducible relation knowable to us only by perception or intuition, then why would he need a principle to tell us if two probabilities are equal? The answer is that for Keynes the Principle of Indifference is *normative*. Keynes's view allows the possibility that one could be mistaken in perceiving indifference, and to accommodate that he has to rely on the Principle of Indifference as a normative principle, which 'endeavours to formulate a rule which will justify judgments of *indifference*.'[@keynes 60] So, the principle serves as a standard of correctness by specifying the conditions under which the uniform distribution of probability among hypotheses is *rational*, i.e., justified. 

To elaborate, recall that the Principle of Indifference was criticized by Peirce due to the paradoxes resulted from following it. When Keynes wrote *A Treatise on Probability*, he was keenly aware of these problematic consequences. However, he thinks that the paradoxes only suggest that the principle is to be restricted, not abandoned altogether. To begin, he notes that the crucial terms used in the principle are not clearly defined:

> The principle states that ‘there must be no known reason for preferring one of a set of alternatives to any other.’ What does this mean? What are ‘reasons,’ and how are we to know whether they do or do not justify us in preferring one alternative to another? I do not know any discussion of Probability in which this question has been so much as asked.[@keynes 58]

Instead, he proposes that this clause ought to be explicated in terms of conditional relevance. That is, to say that we have no reason to prefer a proposition $H$ over its alternatives is to say that there is no evidence such that it is relevant to $H$ but irrelevant to all the alternatives. Roughly speaking, $E$ is relevant to $H$ on background knowledge $K$ if and only if:
$$P(H|K) \neq P(H|K\wedge E)$$
According to Keynes, one necessary condition for a justified application of Indifference is that for a set of $n$ possible outcomes, $H_1,...H_n$, there is no evidential proposition $E$ such that it is conditionally relevant to some but not others. 

The relevance criterion is necessary but not sufficient, because the paradoxes need to be dealt with. 
He argues that the Principle of Indifference should not be used when the alternatives under consideration can be further analyzed, or, using his term, "divisible". Consider again the marble example. The paradox begins with the assumption that red and not red are the two alternatives. While it is true that these outcomes are exhaustive, "not red" should be analyzed before we distribute the probabilities, since it also encompasses the possibility that it is black, it is blue, etc. So according to Keynes' conditions, judging $P(R) = P(\neg R) = 0.5$ is unjustified, since it is not a legal application of the Principle of Indifference. 

With Keynes' version of the principle, we have to know a great deal about the setup of the sample space, before even entertaining the possibility of indifference between alternatives. According to Keynes' proposal, this means that most of our intuitive judgments of indifference would be illicit. In fact, Keynes admits just as much: he holds that in many if not most scenarios, the probability of a given event cannot be given a precise value. For many propositions, it would be impossible to say anything about their probability at all. Of course, Keynes is not saying that it is psychologically impossible for us to have degrees of belief for a proposition that fails to satisfy these conditions, but he is saying that they would not be *rational* degrees of belief. 

## Coherence and Reasonable Degrees of Belief

Ramsey does not seem to share these concerns: he rejects both the Principle of Indifference and Keynes' strongly normative conception of rational degrees of belief: 

> the Principle of Indifference can now be altogether dispensed with; we do not regard it as belonging to formal logic to say what should be a man's expectation of drawing a white or a black ball from an urn; his original expectations may within the limits of consistency be any he likes; all we have to point out is that if he has certain expectations he is bound in consistency to have certain others. This is simply bringing probability into line with ordinary formal logic, which does not criticize premisses but merely declares that certain conclusions are the only ones consistent with them.

Thus Ramsey recognizes the normative nature of Keynes' use of the principle: it constrains our beliefs such that when the conditions for Indifference are met, you *should* assign equal probabilities to the outcomes, otherwise you are *irrational*. As the quote above makes clear, Ramsey's view makes no such demand. As far as he is concerned, it is not probability's business to tell people what degrees of belief they *should* have. Instead, the normative force of probability is the same as that of deductive logic: it serves as a tool of checking consistency of a set of beliefs, and no more. 

Ramsey, then, is advocating what came to be the standard notion of Bayesian rationality: coherence. The question has shifted from "what are rational degrees of belief?" to "is this set of partial beliefs consistent?" Ramsey's analogy to deductive logic is helpful. Consider this argument: 

1. All Chinese are Martians.
2. Socrates is Chinese. 
3. $\therefore$ Socrates is a Martian.

Even though the argument contains all false claims, from a deductive perspective, it is a perfectly valid argument. In the same way, if we have a definitely fair coin but an agent decides that $P(Heads)=0.999$, she is still rational as long as she also believes $P(Tails) = 0.001$. This normative point is perhaps the most influential among the ideas from "Truth and Probability," as Ramsey gestures toward the use of Dutch book arguments in support of coherence as a requirement of rationality: anyone who violates the axioms of probability "could have a book made against him by a cunning better and would then stand to lose in any event."[@ramsey] We have already mentioned van Fraassen's use of Dutch book arguments in support of Reflection, but what Ramsey has in mind is probably simpler than that. The argument is based on the assumption that the agent's willingness to bet is based her degrees of belief and utility function, so an inconsistent set of partial beliefs would imply contradictory betting behavior that could be exploited.

For instance, if the agent believe than $P(Heads) = 0.999$ yet also simultaneously holding that $P(Tails) = 0.5$ This means, based on the assumptions required by Dutch book arguments, you would be willing to pay respectively \$0.999 and \$0.5 for a bet that pays \$1. So, if a bookie offers the agent both bets at those prices, which comes to the total of \$1.499, these bets should appear to be fair, based on her degrees of belief. But she is guaranteed to lose money from this deal, since landing on heads and on tails are mutually exclusive, she will win at most \$1, so she lose $1.499 - 1 = 0.499$ for sure. This is due to the fact that she violates the axiom of probability that says that the sum of the probability of each possible outcome has to be $1$.[@hajekdutchbook 176]


I do not wish to dispute the effectiveness of Dutch book arguments here. Let us for the sake of argument assume that probabilistic coherence is a basic requirement of rationality, because the problem I would like to address is aspects of rationality unaccounted for in Ramsey's view, even if we grant the use of Dutch book arguments, that is, is coherence a sufficient substitute for a normative conception of degrees of belief? L. J. Savage, a strong advocate of Bayesianism and subjective probability, expresses his doubts about whether consistency is enough:

> According to the personalistic view, the role of the mathematical theory of probability is to enable the person using it to detect inconsistencies in his own real or envisaged behavior. It is also understood that, having detected an inconsistency, he will remove it. An inconsistency is typically removable in many different ways, among which the theory gives no guidance for choosing.[@savage, p.57]

Savage's point can be illustrated by considering the Dutch book case above: suppose the subject is convinced that her degrees of belief, $P(Heads) = 0.999$ and $P(Tails) = 0.5$ are incoherent: what normative conclusion should she draw from this? The only advice Ramsey could give her is that they should add up to 1, but should she lower $P(Heads)$ to $0.5$ or lower $P(Tails)$ to $0.001$? In fact, there are, quite literally, infinite ways to for her to resolve the inconsistency. This illuminates the lacuna left open by a descriptive understanding of degrees of belief, motivated by both an operationalist understanding of pragmatism and a rejection of Keynes' rational degrees of belief. In Keynes' framework, assuming that the conditions for the Principle of Indifference are satisfied, the *only* rational way to evaluate these probabilities is $P(Heads) = P(Tails) = 0.5$.








Ramsey attempts to address this normative gap in the very last section of "Truth and Probability," The result is mixed, but directly connected to the view I am trying to establish. Two moves in particular are important to our discussion. Ramsey begins with a plea for a more realistic conception of probabilistic rationality: Keynes' picture of rationality, Ramsey argues, is too stringent. As it requires as a necessary condition that rational degrees of belief must be justified by logically derived *a priori* probabilities, our actual probabilistic judgment are rarely rational by Keynes' light, and this is something Keynes recognizes, hence he holds that many probabilities are either imprecise or unknowable. What we need, Ramsey suggests is a conception of rationality that takes into consideration "the human mind and what is the most we can ask of it."[@ramsey] 

Ramsey's proposal is a theory of *reasonable* degrees of belief, i.e., "human logic", which

>  is a kind of pragmatism: we judge mental habits by whether they work, i.e. whether the opinions they lead to are for the most part true, or more often true than those which alternative habits would lead to.

It is evident that this theory of reasonable degrees of belief has two components: an appealing to pragmatism, and an appeal to the frequency of success in the long run. 

One interpretation of what Ramsey has in mind is that this is essentially his reading of Peirce, and this is supported by Ramsey's own admission that his idea of reasonable degrees of belief "is almost entirely based on the writing of C. S. Peirce", especially the collection of essays published in *Popular Science Monthly*.[@ramsey] 

But what this entail is far from clear. The immediate problem is that Peirce's view on degrees of belief is largely negative, due to his criticism of conceptualism, so it is hard to directly transpose his view in the context of subjective probability. Further, that reasonable degrees of beliefs are useful mental habits is clearly reference to Peirce's pragmatic conception of belief, but to explicate reasonableness as being useful is suggestive of a crude, "whatever works", pragmatism that is usually mis-attributed to Peirce.

The mathematical reading 

Ramsey explicitly credits Peirce: his remark

Keynes' assessment of his debate with Ramsey is telling:

> [According to Ramsey,] the basis of our degrees of belief... is part of our human outfit, perhaps given us merely by natural selection, analogous to our perception and our memories rather than to formal logic. So far I yield to Ramsey---I think he is right. But in attempting to distinguish "rational" degrees of belief from belief in general he was not yet, I think, quite successful. It is not getting to the bottom of the principle of induction merely to say that it is a useful mental habit[@keynesbio 300-301]


To be sure, the purpose of my discussion of Keynes' conception of rational degrees of belief and his Principle of Indifference is not to defend them. There are still more conceptual issues that escape even Keynes' version of the principle.[@joycehpre sec. 6] What I want to demonstrate, however, is that the important normative questions that Keynes attempted to address are still unresolved. 

However, as we shall see, I agree with Ramsey's proposal that the demand for *rational* degrees of belief is too strong: as Keyes himself acknowledges, the severe limited applicability of the Principle of Indifference means that X, so this in practical also means that Keynes' framework cannot provide normative guidance in most our of dealings with uncertainty. The solution is that, instead of asking what *the* universally correct and rational set of degrees of belief is, we should ask what degrees of belief can *reasonably defended*: the difference is that the possibility of reasonable disagreement: X

I disagree, however, with Ramsey's appeal to a crude pragmatism: Keynes is right in saying that it will not do just to say an opinion is reasonable as long as it is useful. Not only is it philosophically unsatisfactory, but it is also a misreading of Peirce's pragmatism. Peirce's view, as we shall see, is without a doubt emphasizes the practical consequences of belief, but it does not mean that its rationality is nothing but its utility. 



<!-- 
### Empiricism as a Matter of the Will

Historically, empiricism is often associated with a flavor of foundationalism that holds that empirical evidence must in some sense be untainted - if experience is to serve as the objective foundation of knowledge, it must be unsullied by our attitudes, beliefs, and values. Quine is arguably the last great empiricist in this tradition: even though he rejected the analytic/synthetic distinction in "Two Dogmas of Empiricism", he has never given the empiricist project: in his very last major work, "From Stimulus to Science", he still pursues the foundationalist project under the disguise of naturalism, by suggesting ways in which the basis of science can be reduced to the firing of neural receptors.[@quinefromstim 15-16]

However, there is also a tradition within empiricism that is antithetical to foundationalism: one that emphasizes the role of decision, intention, and volition in our practice of knowledge. Such an attitude permeates through Carnap's work. *The Logical Structure of the World*, also known by its German title *Aufbau*, is often considered as his most reductionistic work, as its aim is “a step-by-step derivation or ’construction’ of all concepts from certain fundamental concepts...”[@aufbau 5] However, even though his aim was to explicate all concepts in terms of sense experience, there is nothing metaphysically necessary about this design decision---its appropriateness depends ultimately on the decider's "standpoint".[@aufbau 94-95]

In *The Logical Syntax of Language*, he codifies this normative stance as *the Principle of Tolerance*: 

>*It is not our business to set up prohibitions, but to arrive at conventions... In logic, there are no morals.* Everyone is at liberty to build up his own logic, i.e., his own form of language, as he wishes. All that is required of him is that, if he wishes to discuss it, he must state his methods clearly...[@logicalsyntax 51-51]

This was evidently prompted by the disputes between logicians and mathematicians regarding the "correct" language of logic. But the standard of correctness does not exist until a language is chosen, so in an important sense, trying to determine which language is better than another is ultimately futile. However, once we adopt the Principle of Tolerance, "before us lies the boundless ocean of unlimited possibilities."[@logicalsyntax p.xv, p.50] 

In *the Logical Foundation of Probability*, Carnap provides the same analysis on the rift within the probability and statistics: various accounts of probability, offered by Frequentists and Bayesians, have been offered as a candidate to be the true conception of probability, but often the argument from one side would assume a meaning of the term "probability" that simply begs the question against the others, because the pre-scientific use of the word does not correspond strictly to either just "credence" or "chance". [@carnapprob 25] Because of this, the two camps often talk past each other: Frequentists, like Von Mises, would refuse to accept any talk of single case probability as being meaningful, whereas Harold Jeffreys, a Bayesian, would insist that *all* working statisticians are really talking about degrees of belief without even realizing that's what they are doing. What we have is a linguistic stalemate, caused by two sides trying to criticize each within their own framework with their own concept of probability. The result, as Carnap puts it engagingly, is that "neither has anything but ironical remarks for the concept proposed by the other."[@carnaptwoconcepts 517] 

In a later work “Empiricism, Semantics, and Ontology”, Carnap expresses a view that we can call *linguistic voluntarism*, because it takes the role of linguistic framework as central to the analysis of philosophical problems.[@carnapsemantic 206] In particular, Carnap argues that we should distinguish two kinds of questions: ones *internal* to a framework and ones *external* to it.  

Carnap holds that, before any investigation about the world must be made, the investigator must first decide on a linguistic framework, which determines the norms and rules that govern the rationality of the inquiry. One primitive example is our pre-scientific language about the physical world, which Carnap calls the "thing language."[@carnapsemantic 207] It is ill-suited to serious scientific endeavors, but it nevertheless provides enough resources to resolve questions about involving reality of things, such as: 

1. Is it really raining now?
2. Did King Author actually live?
3. Are unions and centaurs real or imaginary?

These questions are internal questions, because they are in principle answerable using the linguistic resources internal to our everyday language, such as rules regarding how we may use experience as evidence for the existence for these objects. By this, Carnap does not mean that there are codified rules we follow consciously, but he assumes that any competent user of the thing language would have some understanding of how these sorts of questions can be answered, by appealing to empirical confirmation. This is not to say the thing language cannot or need not be improved. Historical questions such as whether King Author lived would require us to determine what sort of empirical evidence could be regarded as relevant, but this takes place and draws on the resources available in the thing language, such as the notion of confirmation, evidence, etc.  

However, philosophical questions, such as whether the reality is really real, are *external* questions. The thought is that the normative standard implied by the concept of reality has an intended domain that includes things *in* the world. So the framework breaks down when philosophers try to use the normative standard implied by the concept of reality onto reality itself. But the problem is that to say that something is real presupposes the possibility of some degrees of empirical adequacy, which presupposes a reality that we live in and experience. This is why the language breaks down when philosophers asks external questions about the reality of reality itself. 

Early Wittgenstein seems to be saying that external questions are pseudo-statements: "the limits of my language means the limits of the world" (5.6), so that "what we cannot speak about we must pass over in silent" (7). Carnap, however, does not think such questions are non-sense. The key is that we have to recognize questions external to the framework are *practical* questions about the acceptance of the framework. Thus, instead of asking if the world exists, philosophers, Carnap thinks, are really ask whether the thing language is an adequate tool for its intended goal. Since "thing language in the customary form works indeed with a high degree of efficiency for most purposes of everyday life," one can be justified in choosing it to conduct everyday life. But this acceptance is not required - we are also free to adopt a different language - one may, for instance, choose a language whose structure is based on solipsistic phenomenalism - reducing all talks of physical things to sense impressions. The choice between these competing frameworks is made by considering their "efficiency as instruments."[@carnapsemantic 221]

Even though Carnap does not play an explicit role in any of the main chapter, there are three ways in which his philosophy has influenced the view presented in this dissertation, insofar as that it would not be inaccurate to say that it is defending a Carnapian position. 

First, Carnap's linguistic voluntarism frames much of the way in which I would like to interpret Peirce's notion of abduction. The parallel I'd like to draw is, roughly, that what Carnap calls external questions are analogous to the sort of questions that arise during the abductive stage of inquiry, though in a more localized manner. 

Second, concerns regarding making the acceptance of an opinion, the commitment in a normative standard, and the freedom of thought will be central to our discussion of van Fraassen's voluntarism and the Reflection Principle. This is not an accident. Carnap's overarching philosophical attitude is a precursor to van Fraassen's voluntarism. Van Fraassen himself is explicit about this:

 -->